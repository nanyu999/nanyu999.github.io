# 1. Spark简介

Spark是用于**大规模数据分析的统一引擎**，是一种多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习。

Spark官网：https://spark.apache.org/

技术栈数据统计：[stackoverflow](https://insights.stackoverflow.com/trends?tags=apache-spark%2Chadoop%2Chive%2Cpyspark%2Capache-kafka%2Capache-flink%2Chbase%2Capache-beam%2Chdfs%2Cmapreduce)

